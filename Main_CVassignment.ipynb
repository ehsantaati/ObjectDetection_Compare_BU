{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models as net # cloned from https://github.com/eriklindernoren/PyTorch-YOLOv3\n",
    "import utils as utls\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2, json, mimetypes, pdb, PIL, requests\n",
    "from torchvision import transforms, utils\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = 'config/yolov3.cfg' # loading configuration file\n",
    "weight_file = 'weights/yolov3.weights' # lodeing pre-trained weights\n",
    "class_path = 'data/coco.names'\n",
    "img_size=416 # input image size\n",
    "conf_thres=0.8\n",
    "nms_thres=0.4\n",
    "Tensor = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.Darknet(cfg_file,img_size=img_size)\n",
    "model.load_darknet_weights(weight_file)\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "class_names = utls.utils.load_classes(class_path) # MSCOCO CLass names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading Frames list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'mergedlbls.csv'\n",
    "frames_list = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>im_name</th>\n",
       "      <th>class_id</th>\n",
       "      <th>Xc</th>\n",
       "      <th>Yc</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RainyDay2/00081.jpg</td>\n",
       "      <td>truck</td>\n",
       "      <td>1011</td>\n",
       "      <td>594</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RainyDay2/00082.jpg</td>\n",
       "      <td>truck</td>\n",
       "      <td>1006</td>\n",
       "      <td>599</td>\n",
       "      <td>54</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RainyDay2/00083.jpg</td>\n",
       "      <td>truck</td>\n",
       "      <td>1007</td>\n",
       "      <td>600</td>\n",
       "      <td>60</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RainyDay2/00084.jpg</td>\n",
       "      <td>truck</td>\n",
       "      <td>1006</td>\n",
       "      <td>603</td>\n",
       "      <td>58</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RainyDay2/00085.jpg</td>\n",
       "      <td>truck</td>\n",
       "      <td>1007</td>\n",
       "      <td>598</td>\n",
       "      <td>52</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               im_name class_id    Xc   Yc   w   h\n",
       "0  RainyDay2/00081.jpg    truck  1011  594  56  58\n",
       "1  RainyDay2/00082.jpg    truck  1006  599  54  59\n",
       "2  RainyDay2/00083.jpg    truck  1007  600  60  71\n",
       "3  RainyDay2/00084.jpg    truck  1006  603  58  62\n",
       "4  RainyDay2/00085.jpg    truck  1007  598  52  66"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting the class names and indexes based on MSCOCO's classes names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, ['car'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2i= {'car':2,'truck':7,'bus':5,'motorcycle':3} # object classes\n",
    "i2c = lambda i : [k for k,v in c2i.items() if v ==i] # convert values to classes\n",
    "c2i['car'], i2c(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image(img):\n",
    "    # scale image\n",
    "    ratio = min(img_size/img.size[0], img_size/img.size[1])\n",
    "    imw = round(img.size[0] * ratio)\n",
    "    imh = round(img.size[1] * ratio)\n",
    "    \n",
    "    return imh,imw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3777d9bc40bb41b4abf4575400856756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3570.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the YOLOV3 on the 3570test images: 18.12%\n",
      "\n",
      "True Positives:647\n",
      "False Positives:183\n",
      "\n",
      "Accuracy of car: 30.90%\n",
      "Accuracy of truck: 8.21%\n",
      "Accuracy of bus: 5.56%\n",
      "Accuracy of motorcycle: 0.00%\n"
     ]
    }
   ],
   "source": [
    "class_correct = {'car':0,'truck':0,'bus':0,'motorcycle':0}\n",
    "class_total = {'car':0,'truck':0,'bus':0,'motorcycle':1} # total predicted classes\n",
    "\n",
    "root_dir = 'Frames/'\n",
    "correct = 0\n",
    "detected = 0\n",
    "not_detected = 0\n",
    "\n",
    "for image in trange(frames_list.shape[0]):\n",
    "    img_path = os.path.join(root_dir,frames_list.iloc[image,0]) # finding the path of an image\n",
    "    \n",
    "    img = PIL.Image.open(img_path)  # reading the image\n",
    "    cls_name = frames_list.iloc[image,1] # class name\n",
    "    y = c2i[cls_name] # convert to intiger\n",
    "    \n",
    "    imh,imw = detect_image(img)\n",
    "    \n",
    "    img_transforms=transforms.Compose([transforms.Resize((imh,imw)), # resize, pad and transform to tensor\n",
    "         transforms.Pad((max(int((imh-imw)/2),0), \n",
    "              max(int((imw-imh)/2),0), max(int((imh-imw)/2),0),\n",
    "              max(int((imw-imh)/2),0)), (128,128,128)),\n",
    "         transforms.ToTensor(),\n",
    "         ])\n",
    "    # transforming image to tensor \n",
    "    # https://towardsdatascience.com/object-detection-and-tracking-in-pytorch-b3cf1a696a98\n",
    "    image_tensor = img_transforms(img).float()  \n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input_img = Variable(image_tensor.type(Tensor))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        detections = model(input_img)\n",
    "               \n",
    "        detections  = utls.utils.non_max_suppression(detections, conf_thres, nms_thres)\n",
    "        if detections[0] is not None:\n",
    "            ypred = detections[0][0][6].numpy().tolist()\n",
    "            class_total[cls_name] +=ypred\n",
    "            if ypred ==y:\n",
    "                class_correct[i2c(y)[0]] +=1\n",
    "                correct +=1\n",
    "              \n",
    "            \n",
    "        else:\n",
    "             not_detected+=1\n",
    "            \n",
    "         \n",
    "    \n",
    "        \n",
    "print(f'Accuracy of the YOLOV3 on the {frames_list.shape[0]}test images: {100 * correct / frames_list.shape[0]:0.2f}%\\n'\n",
    "    \n",
    ")\n",
    "\n",
    "print(\n",
    "    f'True Positives:{correct}\\nFalse Positives:{frames_list.shape[0]-not_detected-correct}\\n'\n",
    ")\n",
    "\n",
    "for k,v in class_correct.items():\n",
    "    cls_acc = 100 * class_correct[k]/class_total[k]\n",
    "    print(f'Accuracy of {k}: {cls_acc:0.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
